#!/usr/bin/env python3
"""
Compute KPIs from CSV files and write daily metrics.

Expected CSV files in data directory:
- billing.csv: date, amount, status
- ads_spend.csv: date, spend
- new_customers.csv: date, new_customers
- cohorts.csv (optional): cohort retention data

Outputs:
- data/metrics/<YYYY-MM-DD>.md: Daily metrics report
"""

import argparse
import csv
import json
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional


def validate_csv(filepath: Path, required_columns: List[str]) -> bool:
    """Validate CSV has required columns and proper format."""
    if not filepath.exists():
        return False
    
    try:
        with open(filepath, 'r') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames or []
            
            # Check required columns
            for col in required_columns:
                if col not in headers:
                    print(f"Error: Missing column '{col}' in {filepath.name}")
                    return False
            
            # Validate at least one data row
            rows = list(reader)
            if not rows:
                print(f"Warning: No data rows in {filepath.name}")
                return False
                
            # Validate date format and numeric values
            for i, row in enumerate(rows):
                try:
                    datetime.strptime(row['date'], '%Y-%m-%d')
                except ValueError:
                    print(f"Error: Invalid date format in {filepath.name} row {i+2}: {row['date']}")
                    return False
                    
        return True
    except Exception as e:
        print(f"Error validating {filepath.name}: {e}")
        return False


def load_csv_data(filepath: Path) -> List[Dict]:
    """Load CSV data into list of dictionaries."""
    data = []
    with open(filepath, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            data.append(row)
    return data


def compute_mrr(billing_data: List[Dict], target_date: Optional[str] = None) -> float:
    """Compute Monthly Recurring Revenue (MRR) from billing data."""
    if target_date is None:
        target_date = datetime.now().strftime('%Y-%m-%d')
    
    # Sum all active subscriptions up to target date
    mrr = 0.0
    for row in billing_data:
        if row['date'] <= target_date and row['status'] == 'active':
            mrr += float(row['amount'])
    
    return mrr


def compute_cac(ads_spend_data: List[Dict], new_customers_data: List[Dict], 
                days: int = 30) -> float:
    """Compute Customer Acquisition Cost (CAC) over specified period."""
    cutoff_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
    
    total_spend = sum(float(row['spend']) for row in ads_spend_data 
                      if row['date'] >= cutoff_date)
    total_customers = sum(int(row['new_customers']) for row in new_customers_data 
                         if row['date'] >= cutoff_date)
    
    if total_customers == 0:
        return 0.0
    
    return total_spend / total_customers


def compute_d30_retention(cohorts_data: Optional[List[Dict]] = None) -> float:
    """
    Compute D30 retention rate.
    For now, returns a placeholder if cohorts.csv doesn't exist.
    """
    if not cohorts_data:
        # Return a reasonable placeholder
        return 85.0
    
    # TODO: Implement actual cohort retention calculation
    # This would need proper cohort analysis based on cohort structure
    return 85.0


def write_metrics_file(output_path: Path, metrics: Dict, metadata: Dict) -> None:
    """Write metrics to markdown file."""
    content = f"""# Daily Metrics — {metadata['date']}

**Generated:** {metadata['timestamp']}

## Key Performance Indicators

### Growth Metrics
- **MRR (Monthly Recurring Revenue):** €{metrics['mrr']:.2f}
- **CAC (Customer Acquisition Cost):** €{metrics['cac']:.2f}
- **D30 Retention Rate:** {metrics['d30_retention']:.1f}%

### Data Summary
- Billing records processed: {metadata['billing_rows']}
- Ad spend records: {metadata['ads_spend_rows']}
- New customers records: {metadata['new_customers_rows']}

### Insights
{metadata.get('insights', 'No insights generated.')}

---

*Generated by compute_kpis.py*
"""
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w') as f:
        f.write(content)


def check_alerts(metrics: Dict, previous_metrics: Optional[Dict], 
                 config: Dict, alerts_path: Path) -> None:
    """Check if metrics exceed thresholds and queue alerts."""
    if not previous_metrics:
        return
    
    thresholds = config.get('thresholds', {})
    cac_threshold = thresholds.get('cac_pct_swing', 20)
    d30_threshold = thresholds.get('d30_pct_swing', 20)
    
    alerts = []
    
    # Check CAC swing
    if previous_metrics.get('cac', 0) > 0:
        cac_change = ((metrics['cac'] - previous_metrics['cac']) / 
                      previous_metrics['cac']) * 100
        if abs(cac_change) >= cac_threshold:
            alerts.append({
                'timestamp': datetime.now().isoformat(),
                'metric': 'CAC',
                'value': metrics['cac'],
                'previous_value': previous_metrics['cac'],
                'change_pct': cac_change,
                'threshold': cac_threshold,
                'message': f"CAC changed by {cac_change:.1f}%"
            })
    
    # Check D30 retention swing
    if previous_metrics.get('d30_retention', 0) > 0:
        d30_change = ((metrics['d30_retention'] - previous_metrics['d30_retention']) / 
                      previous_metrics['d30_retention']) * 100
        if abs(d30_change) >= d30_threshold:
            alerts.append({
                'timestamp': datetime.now().isoformat(),
                'metric': 'D30_Retention',
                'value': metrics['d30_retention'],
                'previous_value': previous_metrics['d30_retention'],
                'change_pct': d30_change,
                'threshold': d30_threshold,
                'message': f"D30 retention changed by {d30_change:.1f}%"
            })
    
    # Write alerts to queue
    if alerts:
        alerts_path.parent.mkdir(parents=True, exist_ok=True)
        with open(alerts_path, 'a') as f:
            for alert in alerts:
                f.write(json.dumps(alert) + '\n')


def main():
    parser = argparse.ArgumentParser(description='Compute KPIs from CSV files')
    parser.add_argument('--data-dir', type=str, default='data',
                        help='Data directory path (default: data)')
    parser.add_argument('--write', action='store_true',
                        help='Write metrics file to disk')
    parser.add_argument('--date', type=str, default=None,
                        help='Target date (YYYY-MM-DD, default: today)')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Verbose output')
    
    args = parser.parse_args()
    
    # Setup paths
    data_dir = Path(args.data_dir)
    billing_csv = data_dir / 'billing.csv'
    ads_spend_csv = data_dir / 'ads_spend.csv'
    new_customers_csv = data_dir / 'new_customers.csv'
    cohorts_csv = data_dir / 'cohorts.csv'
    config_file = data_dir / 'config' / 'alerts.json'
    
    target_date = args.date or datetime.now().strftime('%Y-%m-%d')
    
    # Validate inputs
    if args.verbose:
        print(f"Validating CSV files in {data_dir}...")
    
    if not validate_csv(billing_csv, ['date', 'amount', 'status']):
        print(f"Error: Invalid or missing {billing_csv}")
        sys.exit(1)
    
    if not validate_csv(ads_spend_csv, ['date', 'spend']):
        print(f"Error: Invalid or missing {ads_spend_csv}")
        sys.exit(1)
    
    if not validate_csv(new_customers_csv, ['date', 'new_customers']):
        print(f"Error: Invalid or missing {new_customers_csv}")
        sys.exit(1)
    
    # Load data
    if args.verbose:
        print("Loading CSV data...")
    
    billing_data = load_csv_data(billing_csv)
    ads_spend_data = load_csv_data(ads_spend_csv)
    new_customers_data = load_csv_data(new_customers_csv)
    cohorts_data = load_csv_data(cohorts_csv) if cohorts_csv.exists() else None
    
    # Load config
    config = {}
    if config_file.exists():
        with open(config_file, 'r') as f:
            config = json.load(f)
    
    # Compute metrics
    if args.verbose:
        print("Computing KPIs...")
    
    metrics = {
        'mrr': compute_mrr(billing_data, target_date),
        'cac': compute_cac(ads_spend_data, new_customers_data),
        'd30_retention': compute_d30_retention(cohorts_data)
    }
    
    # Print results
    print(f"\n=== KPIs for {target_date} ===")
    print(f"MRR: €{metrics['mrr']:.2f}")
    print(f"CAC: €{metrics['cac']:.2f}")
    print(f"D30 Retention: {metrics['d30_retention']:.1f}%")
    
    # Write to file if requested
    if args.write:
        output_path = data_dir / 'metrics' / f'{target_date}.md'
        metadata = {
            'date': target_date,
            'timestamp': datetime.now().isoformat(),
            'billing_rows': len(billing_data),
            'ads_spend_rows': len(ads_spend_data),
            'new_customers_rows': len(new_customers_data),
            'insights': f"MRR is on track. CAC is €{metrics['cac']:.2f} per customer."
        }
        
        write_metrics_file(output_path, metrics, metadata)
        print(f"\n✓ Metrics written to {output_path}")
        
        # Check for alerts
        # Try to load previous day's metrics for comparison
        previous_date = (datetime.strptime(target_date, '%Y-%m-%d') - 
                        timedelta(days=1)).strftime('%Y-%m-%d')
        previous_metrics_file = data_dir / 'metrics' / f'{previous_date}.md'
        
        # For alerts, we'd need to parse previous metrics or store them in JSON
        # For now, skip alert checking in first run
        alerts_path = data_dir / 'alerts' / 'outbox.jsonl'
        if previous_metrics_file.exists() and args.verbose:
            print("Alert checking not implemented yet (requires previous metrics)")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())

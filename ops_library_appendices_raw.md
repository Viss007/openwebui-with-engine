# Ops Library â€” Appendices (Viss Command Center)

This library holds detailed specs, templates, and long-form guidance referenced by the **Core Manual**. Keep the Core Manual lean; put heavy reference here.

**Last updated:** 2025â€‘09â€‘07 Â· **Owner:** Viss Â· **Scope:** reference only (no background work).

## Upgrade Policy â€” command protocol

Use oneâ€‘line commands to request changes. Iâ€™ll return patches and, if needed, a full updated file and a revert block.

```
UPGRADE REQUEST
doc: <Ops Library>
scope: <section|full>
confirm: yes
```

**Rules**

- â• *Additive first* (insert/update sections). For structural changes, Iâ€™ll summarize diffs and ask to proceed.
- âœ‚ï¸ *Microâ€‘fixes autoâ€‘apply* (typos/links/spacing). All risky writes (billing/DNS/marketplace) **require approval**.
- ğŸ§¾ **Provenance stays visible**; deep specs live here; Core Manual remains lean.

**Examples**

- ğŸ”§ `UPGRADE REQUEST doc: Ops Library scope: full confirm: yes`
- ğŸ”§ `UPGRADE REQUEST doc: Ops Library scope: section=Appendix B â€” KPI wiring confirm: yes`

---

## Provenance & Source Disclosure (alwaysâ€‘on)

- ğŸ§¾ In any response that relies on **files/canvases**, include a oneâ€‘liner at the top or bottom:\
  `Source: <name> Â· <path or â€œcanvasâ€> Â· <lastâ€‘updated if known>`
- ğŸ§¾ If **multiple sources**, list each on its own line.
- ğŸŒ If the response uses **web browsing**, keep normal citations and add:\
  `Source: web (see citations)`
- ğŸ’¬ If the response uses **conversation context only**, say:\
  `Source: conversation context only`
- ğŸ“ For **user uploads** under `/mnt/data`, show the filename and path.

*Example:*\
`Source: Ops Library â€” Appendices (Viss Command Center) Â· canvas`

## Appendix A â€” Specs & Templates

### Custom Actions (HTTP Connectors)

**What they are.** Custom Actions let Viss call your HTTP APIs during a chat. You define them with an **OpenAPI schema**, add auth (API key or OAuth), and the model can invoke them on demand to read/write external systems. They are **pull-only**: the model calls them when you askâ€”no background execution.

**When to use.**

- ğŸ“¥ Pull data from SaaS/services ("check incidents since 09:00").
- âœï¸ Perform writes with confirmation ("create Jira tasks for these 5 bugs").
- ğŸ”„ Bridge to offline Python: Action fetches â†’ Python analyzes â†’ results saved to canvas/disk.

**Limits & safeguards.**

- â›” No background jobs or push notifications from Actions.
- ğŸ Python remains offline; networking must go through Actions or the web tool.
- ğŸ”’ Workspaces can restrict allowed **domains** for Actions; use least-privilege **RBAC** and per-user auth.
- ğŸ“¦ Keep payloads small, return **typed JSON**, and surface clear error messages.
- ğŸ§¾ All Action calls must emit a proof footer and write an audit line to `/mnt/data/.agent_logs/actions.jsonl`.

**Design guidelines.**

- â™»ï¸ Prefer **idempotent** endpoints for repeat calls; include a client-provided `request_id`.
- â†”ï¸ Separate **read** and **write** endpoints; require explicit confirmation before destructive ops.
- ğŸ§­ Version your API (`/v1/â€¦`), set conservative timeouts, and document error semantics.
- ğŸ—‚ï¸ For large binaries, return signed URLs or summariesâ€”donâ€™t inline megabytes.

#### Actions â€” Upgrades

1. ğŸ§° **Error model (standardize):** single JSON error shape with `code`, `message`, `details`, `request_id`, `retry_after`. Map HTTP â†’ action outcomes (200/201, 202 async, 400 user fix, 401/403 auth, 409 conflict/idempotency, 429 rate, 5xx transient).
2. â™»ï¸ **Idempotency & retries:** formalize `Idempotency-Key` (or `request_id`), max attempts, exponential backoff, and when *not* to retry (4xx except 409/429).
3. ğŸ”¢ **Pagination & limits:** `?limit`/`?cursor` and response envelope; cap payload (e.g., 200 items/2 MB).
4. ğŸ‘ï¸ **Observability:** require `X-Request-ID` passthrough, structured logs (no secrets), redaction rules, audit tags (who/why).
5. ğŸ” **Security baseline:** domain allowlist, TLS only, short timeouts (8â€“15 s), strict schemas (fail-closed), role-scoped tokens, key rotation cadence.
6. â³ **Async jobs:** allow 202 + `status_url` for long writes; forbid hidden background pushes.
7. ğŸ§‘â€ğŸ’» **UX contracts:** for writes, require explicit confirmation text, support **dry-run**, and summarize side-effects.
8. âœ… **Testing:** ship a mock server + fixtures; include negative cases (429, 409, schema mismatch).

#### Action Manifest (drop-in)

```json
{
  "name": "viss-actions",
  "base_url": "https://api.example.com",
  "auth": {"type": "api_key", "header": "X-API-Key"},
  "allow_domains": ["api.example.com"],
  "timeout_seconds": 12,
  "retries": {"max_attempts": 3, "backoff": "exponential", "max_delay_seconds": 20, "retry_on": [429, 502, 503, 504]},
  "redaction": {"headers": ["Authorization","X-API-Key"], "fields": ["token","password"]},
  "idempotency": {"header": "Idempotency-Key"},
  "pagination": {"param": "cursor", "limit_param": "limit", "max_limit": 200},
  "limits": {"max_body_bytes": 2097152}
}
```

#### OpenAPI skeleton (upgraded)

```yaml
openapi: 3.1.0
info: { title: Viss Actions, version: 1.1.0 }
servers: [ { url: https://api.example.com } ]
components:
  securitySchemes:
    ApiKeyAuth: { type: apiKey, in: header, name: X-API-Key }
    OAuth2:
      type: oauth2
      flows:
        authorizationCode:
          authorizationUrl: https://auth.example.com/authorize
          tokenUrl: https://auth.example.com/token
          scopes: { tasks: Create and list tasks }
  parameters:
    Cursor: { name: cursor, in: query, schema: { type: string } }
    Limit:  { name: limit,  in: query, schema: { type: integer, minimum: 1, maximum: 200 }, required: false }
  headers:
    RequestID: { schema: { type: string }, description: Server-assigned request id }
    RetryAfter: { schema: { type: integer }, description: Seconds until safe retry }
    RateLimitRemaining: { schema: { type: integer } }
    IdempotencyKey: { schema: { type: string } }
  schemas:
    Error:
      type: object
      required: [code, message]
      properties:
        code: { type: string }
        message: { type: string }
        details: { type: object, additionalProperties: true }
        request_id: { type: string }
        retry_after: { type: integer, nullable: true }
    Update:
      type: object
      properties:
        id: { type: string }
        title: { type: string }
        changed_at: { type: string, format: date-time }
    Task:
      type: object
      properties:
        id: { type: string }
        title: { type: string }
        description: { type: string }
paths:
  /updates:
    get:
      summary: List updates since timestamp
      security: [ { ApiKeyAuth: [] } ]
      parameters:
        - { name: since, in: query, schema: { type: string, format: date-time } }
        - $ref: '#/components/parameters/Cursor'
        - $ref: '#/components/parameters/Limit'
      responses:
        '200':
          description: OK
          headers:
            Request-ID: { $ref: '#/components/headers/RequestID' }
            RateLimit-Remaining: { $ref: '#/components/headers/RateLimitRemaining' }
          content:
            application/json:
              schema:
                type: object
                properties:
                  ok: { type: boolean }
                  next_cursor: { type: string, nullable: true }
                  data: { type: array, items: { $ref: '#/components/schemas/Update' } }
        '429':
          description: Too Many Requests
          headers: { Retry-After: { $ref: '#/components/headers/RetryAfter' } }
          content: { application/json: { schema: { $ref: '#/components/schemas/Error' } } }
        '4XX':
          description: Client Error
          content: { application/json: { schema: { $ref: '#/components/schemas/Error' } } }
        '5XX':
          description: Server Error
          content: { application/json: { schema: { $ref: '#/components/schemas/Error' } } }
  /tasks:
    post:
      summary: Create a task (idempotent)
      security: [ { OAuth2: [tasks] } ]
      parameters:
        - in: header
          name: Idempotency-Key
          required: true
          schema: { type: string }
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: [title]
              properties:
                title: { type: string }
                description: { type: string }
      responses:
        '201':
          description: Created
          content: { application/json: { schema: { type: object, properties: { ok: {type: boolean}, task: { $ref: '#/components/schemas/Task' } } } } }
        '202':
          description: Accepted (async)
          content: { application/json: { schema: { type: object, properties: { ok: {type: boolean}, status_url: { type: string, format: uri } } } } }
        '409':
          description: Conflict (duplicate idempotency key)
          content: { application/json: { schema: { $ref: '#/components/schemas/Error' } } }
        '4XX':
          description: Client Error
          content: { application/json: { schema: { $ref: '#/components/schemas/Error' } } }
        '5XX':
          description: Server Error
          content: { application/json: { schema: { $ref: '#/components/schemas/Error' } } }
```

#### Jobs endpoint (async)

```yaml
/jobs/{id}:
  get:
    summary: Get job status
    responses:
      '200':
        content:
          application/json:
            schema:
              type: object
              required: [id, status]
              properties:
                id: { type: string }
                status: { type: string, enum: [queued, running, succeeded, failed] }
                last_error: { type: string, nullable: true }
```

### Recipe â€” Web â†’ Python handoff (short)

*Pointer:* Mirrors **Core Manual â†’ Buttons & Actions â†’ Web â†’ Python handoff** (v1.3.5).

**Default filename:** `<slug>_<YYYY-MM-DD>.<ext>` (date in **Europe/Vilnius**).\
**Directories:** ingest â†’ `/mnt/data/web_ingest/` Â· outputs â†’ `/mnt/data/processed/`

**Exact steps**

1. ğŸ“¥ **Fetch** the URL and save as `/mnt/data/web_ingest/<slug>_<YYYY-MM-DD>.<ext>`.
2. ğŸ§® **Process** offline:
   ```bash
   python /mnt/data/tools/process_web_ingest.py --input /mnt/data/web_ingest --output /mnt/data/processed
   ```
3. ğŸ” **Review** artifacts: `<stem>_clean.csv`, `<stem>_summary.csv` under `/mnt/data/processed/`.
4. ğŸ›¡ï¸ **(If exporting to spreadsheets)** guard against CSV formulas when opening.

**Oneâ€‘liner chat trigger**

> Fetch  as . â†’ Run recipe

---

### JSON variant examples

```python
from pathlib import Path
import json, pandas as pd
p = Path('/mnt/data/web_ingest/example_2025-09-05.json')

# 1) Arrayâ€‘ofâ€‘objects JSON
try:
    df = pd.read_json(p)
except ValueError:
    # 2) {"meta": ..., "data": [...]} shape
    obj = json.loads(p.read_text(encoding='utf-8'))
    df = pd.json_normalize(obj, record_path='data',
                           meta=[["meta","source"], ["meta","fetched_at"]],
                           errors='ignore')

# 3) Deeper nesting with list record_path
# e.g., {"responses": [{"question_id": 1, "choices": [...]}, ...]}
# meta can be a list of dotted paths or list-of-lists
# df = pd.json_normalize(obj, record_path=['responses','choices'],
#                        meta=[["responses","question_id"], ["meta","source"]],
#                        errors='ignore')

# Write a clean CSV
# df.to_csv('/mnt/data/processed/example_2025-09-05_clean.csv', index=False)
```

**Slug rules (quick):** lowercase, digits, dashes only; no spaces; keep under 40 chars. Examples: `outages`, `statuspage_log`, `market-prices`.

---

### Agent Spec (template)

```
### Agent Spec
- Name:
- Command: Agent: <verb phrase>
- Schedule (iCal VEVENT):
- Inputs (data / tools):
- Steps (â‰¤7, each â‰¤1 line):
- Outputs (files/notes):
- Guardrails: max 300 s, ask-before-write, read-only unless approved.
- Log target: /mnt/data/.agent_logs/<name>.jsonl
```

### Example Commands (reference)

```
Sync: toolâ†’mirrors
Sync: mirrorsâ†’tool
Apply --dry-run /mnt/data/getting_started.md
Apply to disk /mnt/data/getting_started.md
Doctor --summary --gzip
Status
# Enforcement
python /mnt/data/tools/pre_apply_lint.py --target /mnt/data/mirror_mnt_data_tool.md --json
python /mnt/data/tools/rotate_artifacts.py --dry-run
# KPIs
python /mnt/data/tools/compute_kpis.py --write
# Agent
python /mnt/data/agents/kpi_ping.py --run-now
# Token estimator
python /mnt/data/tools/token_estimator.py /mnt/data/somefile.txt --window 196000 --output 2000 --headroom 0.10
# Token estimator (JSON, multi-file)
python /mnt/data/tools/token_estimator.py /mnt/data/file1.txt /mnt/data/file2.txt --json
# Web â†’ Python handoff
python /mnt/data/tools/process_web_ingest.py -i /mnt/data/web_ingest -o /mnt/data/processed --guard-csv-injection -v
# Web â†’ Python handoff (JSON deep paths)
python /mnt/data/tools/process_web_ingest.py -i /mnt/data/web_ingest -o /mnt/data/processed \
  --record-path responses.choices --meta responses.question_id --meta meta.source
```

---

## Appendix B â€” KPI wiring & alerts

### Wiring KPIs

- ğŸ”§ **Script:** `/mnt/data/tools/compute_kpis.py`
- ğŸ“¥ **Inputs (expected in ****\`\`****):**
  - ğŸ“„ `billing.csv` â€” columns: `date, amount, status` (EUR; status is one of {active, canceled}).
  - ğŸ“„ `ads_spend.csv` â€” columns: `date, spend`.
  - ğŸ“„ `new_customers.csv` â€” columns: `date, new_customers`.
  - ğŸ“„ `cohorts.csv` (optional) â€” cohort retention table.

**Examples:**

```
# billing.csv
2025-09-04,50.00,active
# ads_spend.csv
2025-09-04,120.00
# new_customers.csv
2025-09-04,3
```

**Preâ€‘validation (ingest)**

- ğŸ§ª Reject files with **nonâ€‘ISO dates** or nonâ€‘numeric amounts; log row numbers.
- ğŸ§° Run `pre_apply_lint` with expected new size; abort on protectedâ€‘path violations.
- ğŸ§¾ Emit a short `ingest_summary.json` (rows accepted/rejected; reasons).

**Sampling windows & retention**

- â±ï¸ **FRT:** daily **median** by date (Europe/Vilnius). Exclude autoâ€‘responders/spam.
- ğŸ“† **D30 resolution:** percent of tickets resolved within **30 calendar days**; compute on rolling 30â€‘day cohorts.
- ğŸ—ƒï¸ **Retention:** keep raw daily aggregates **12 months**; keep monthly rollups **indefinitely**.

**Data quality rules**

- ğŸ“… Dates are ISO `YYYYâ€‘MMâ€‘DD`; amounts are numeric (EUR); `status` âˆˆ {active, canceled}.
- ğŸ” No duplicate dates within a file; missing days are allowed.
- ğŸ“ D30 retention is measured on cohort endâ€‘ofâ€‘window; note any method change in the changelog.

**Outputs**

- ğŸ—“ï¸ Daily metrics: `/mnt/data/metrics/<YYYYâ€‘MMâ€‘DD>.md`.
- ğŸ“ˆ Optional chart: `/mnt/data/metrics/<YYYYâ€‘MMâ€‘DD>_mrr.png` (if billing data present).
- ğŸ“ Templates: installed at `/mnt/data/templates/`.

### Alerts & Quiet Hours

- âš™ï¸ **Config:** `/mnt/data/config/alerts.json`
  - `quiet_hours`: `{ start:"22:00", end:"07:00", tz:"Europe/Vilnius" }`
  - `channels`: `{ webhook_url:null, email:null }` (set one or both to enable push; with no network, alerts are queued locally).
- ğŸ“¨ **Queue:** alerts are written to `/mnt/data/alerts/outbox.jsonl`.
- ğŸ“¤ **Dispatch:** `python /mnt/data/tools/alert_dispatch.py --flush` prints `curl` commands (for webhook) or a plaintext email body you can copy into your mail client.
- ğŸ“Š **Thresholds:** CAC or D30 swing **>20%** (configurable in `alerts.json`).
- ğŸŒ™ **Quiet hours:** during quiet hours, alerts are queued, not flushed; use `--override-quiet-hours` to force.

### Dashboard (HTML)

- ğŸ—ï¸ **Builder:** `/mnt/data/tools/build_dashboard.py`
- ğŸ–¥ï¸ **Output:** `/mnt/data/dashboard/index.html`
- ğŸ“Š **Contents:** latest KPIs, last Doctor summary, last Apply manifest snippet, and (if available) the latest MRR chart image.
- â–¶ï¸ **Run:** `python /mnt/data/tools/build_dashboard.py`

---

## Appendix C â€” Agent Mode & Deep Research

### Agent Mode â€” quickâ€‘start & quotas (card)

**Start:** Open **Agent mode** from the tools menu (or type `/agent`). State the **goal**, any **mustâ€‘use sources**, and **constraints** (time window, budget, accounts).\
**During run:** A visible browser executes steps. You can **approve/deny** actions, **pause/stop**, or **Take over browser** for sensitive inputs.\
**Deliverables:** Summary + any artifacts (docs, sheets, code). Agent may use **Code Interpreter** and **Connectors (readâ€‘only)**.\
**Repeat/schedule:** After completion, choose daily/weekly/monthly; manage runs at **chatgpt.com/schedules**.

**Quotas (typical today):**

| Plan                      | Monthly agent requests                                                        | Notes                                                         |
| ------------------------- | ----------------------------------------------------------------------------- | ------------------------------------------------------------- |
| **Plus**                  | **40**                                                                        | Only the initial agent request counts; followâ€‘ups/auth donâ€™t. |
| **Pro**                   | **400**                                                                       | Same rule as Plus.                                            |
| **Business / Enterprise** | **40** *(or orgâ€‘configured; some flexible pricing list \~30 credits/message)* | Check your admin settings.                                    |

> Limits can change. Reâ€‘verify in OpenAI help center and update this card during monthly link audits.

---

#### Operating rules (workspace)

- ğŸ”€ **Agent vs plain chat:** Use Agent for multiâ€‘step web+action workflows; otherwise plain chat or Deep Research.
- ğŸ›¡ï¸ **Agent safety â€” 3 checks:** (1) Sensitive step? **Take over browser**. (2) Consequential write? **ask & log**. (3) Weird prompts? **pause and confirm**.
- ğŸ¤– **Model picker:** Default **GPTâ€‘5**; **o3** for heavy reasoning; **o4â€‘mini** for speed. *Note:* Canvas/images arenâ€™t available in **GPTâ€‘5 Pro**.
- ğŸŒ **Browse vs Deep Research:** â‰¤60 s quick browse for stable facts; Deep Research for volatile/highâ€‘stakes topics.
- ğŸ›‘ **When to stop:** at **T+300 s**, on **Doctor/Status critical**, or when **preconditions fail** â†’ return partial + next steps, stop.

### Deep Research Mode

**Use when**

- ğŸ§­ The topic is uncertain, niche, or fastâ€‘moving; decisions involve spend or time impact; any claim needs citations.

**Inputs (minimum)**

- ğŸ§© Topic/question; scope/time window; constraints (what to include/exclude); mustâ€‘use sources (optional).

**Process (â‰¤7 steps)**

1. ğŸ¯ Refine the objective into 2â€“3 concrete questions; set scope and time window.
2. ğŸ” Draft 4â€“8 search queries; browse breadth with highâ€‘quality sources first.
3. ğŸŒ Collect 8â€“12 **diverse, authoritative** sources; skip lowâ€‘quality or paywalled summaries.
4. ğŸ“Œ Extract 5â€“10 key facts; label **stable** vs **volatile** and note disagreements.
5. ğŸ§  Synthesize a **Research Brief**: TL;DR, Whatâ€™s Known, Whatâ€™s Uncertain, and Implications/Next Steps.
6. ğŸ“š Cite the 5 most loadâ€‘bearing facts with sources; avoid overâ€‘quoting.
7. ğŸ’¾ Save artifacts and stop (no background work).

**Outputs**

- ğŸ“„ `/mnt/data/research/<slug>/<ts>/brief.md` (the brief)
- ğŸ”— `/mnt/data/research/<slug>/<ts>/sources.json` (URLs and metadata)
- ğŸ§¾ `/mnt/data/research/<slug>/<ts>/evidence.csv` (claims â†” citations)
- ğŸŒ `/mnt/data/research/website/<ts>/â€¦` (websiteâ€‘focused capture for SEO/IA tasks)

**Quality guardrails**

- ğŸ§­ Relevance Â· Diversity Â· Trustworthiness Â· Accurate representation; show disagreements when present.
- â³ 300 s/turn limit; if it wonâ€™t fit, do a safe partial and stop.

**Commands**

- ğŸ§  `Deep Research: <topic> scope:<days> max-sources:<n>`
- ğŸ’¾ `Save Research to disk`

**Preâ€‘code web pass (pointer):** Before any Python, do a â‰¤60s quick doc check (official sources). See **Core Manual â†’ Boot Checklist 2a**.

### Query pack (template)

- ğŸ” `<topic>` site\:docs.\* OR site:\*.org file\:pdf

- ğŸ” `<topic>` "changelog" OR "release notes" site:\*.com

- ğŸ” `<topic>` overview OR comparison (last 30 days)

- ğŸ” `<topic>` standard OR guideline site:.gov OR site\:who.int

- ğŸ” `<topic>` site\:docs.\* OR site:\*.org file\:pdf

- ğŸ” `<topic>` "changelog" OR "release notes" site:\*.com

- ğŸ” `<topic>` overview OR comparison (last 30 days)

- ğŸ” `<topic>` standard OR guideline site:.gov OR site\:who.int

---

## Appendix D â€” Tools & Utilities

### Preâ€‘apply lint

- ğŸ“ **Path:** `/mnt/data/tools/pre_apply_lint.py`
- ğŸ’» **CLI:** `python /mnt/data/tools/pre_apply_lint.py --target <path> [--new-size <bytes>] [--json]`
- ğŸ” **Checks:** target existence (optional), protectedâ€‘path violations, sizeâ€‘delta warnings.

### Rotate artifacts

- ğŸ“ **Path:** `/mnt/data/tools/rotate_artifacts.py`
- ğŸ’» **CLI:** `python /mnt/data/tools/rotate_artifacts.py [--dry-run]`
- ğŸ¯ **Purpose:** Enforce **Retention & Rotation** policy.

### Selfâ€‘Check

- ğŸ“œ **Script:** `/mnt/data/tools/self_check.py`
- ğŸ“ **What it does:** runs `pre_apply_lint` (on a target you pass), `rotate_artifacts --dry-run`, and writes a short report to `/mnt/data/.doctor/self_check_<ts>.md`.
- â–¶ï¸ **Run:** `python /mnt/data/tools/self_check.py --target /mnt/data/mirror_mnt_data_tool.md`



### process\_web\_ingest.py (Web â†’ Python handoff utility)

- ğŸ“ **Path:** `/mnt/data/tools/process_web_ingest.py`
- ğŸ¯ **Purpose:** Scan `/mnt/data/web_ingest/` for new files (**CSV/JSON/NDJSON**), produce `<stem>_clean.csv` + `<stem>_summary.csv` in `/mnt/data/processed/`.
- ğŸ’» **CLI:**
  ```bash
  python /mnt/data/tools/process_web_ingest.py --input /mnt/data/web_ingest --output /mnt/data/processed \
    --guard-csv-injection --verbose
  # Deep JSON paths
  python /mnt/data/tools/process_web_ingest.py -i /mnt/data/web_ingest -o /mnt/data/processed \
    --record-path responses.choices --meta responses.question_id --meta meta.source
  ```
- **Options:**
  - ğŸ“Œ `--record-path <dot.path>` (repeatable) â€” JSON array path (e.g., `responses.choices`).
  - ğŸ§¾ `--meta <dot.path>` (repeatable) â€” keep JSON meta fields (e.g., `meta.source`).
  - ğŸ›¡ï¸ `--guard-csv-injection` â€” prefixes risky cells starting with `= + - @` or TAB.
  - ğŸ“¦ `--chunksize N` â€” stream large CSVs in chunks.
  - ğŸ” `--glob` â€” include patterns (default: `*.csv,*.json,*.ndjson,*.jsonl`).
  - ğŸ—£ï¸ `--verbose` â€” progress logs to stderr.
- **Outputs:**
  - ğŸ§¹ `*_clean.csv` â€” trimmed strings, deduped rows, optional CSVâ€‘injection guard applied.
  - ğŸ“‹ `*_summary.csv` â€” rows, columns, column names, dtype/nonnull/null%, basic min/max for numeric/datetimeâ€‘ish columns.

## Appendix E â€” ChatGPT Pro (workspace)

*Anchor: #appendix-e-chatgpt-pro Â· Last updated: 2025-09-05*

### At a glance

- ğŸ’¡ **What you get:** unlimited access to **GPTâ€‘5** and select legacy models, advanced voice, prioritized traffic.
- ğŸ§° **Guardrails:** "Unlimited" is usageâ€‘policed by OpenAI Terms; **no account sharing**, **no scraping/abusive automation**.
- ğŸ”Œ **API is separate:** OpenAI API is billed separately (different quotas/billing).

### Model picker (Pro)

- ğŸ¤– Default **GPTâ€‘5**; switch to **o3** for heavy reasoning; **o4â€‘mini** for speed.
- ğŸ› ï¸ **Tools note:** Canvas & image generation arenâ€™t available with **GPTâ€‘5 Pro**; use **GPTâ€‘5 Thinking** (or another model) when you need Canvas/images.

### 90â€‘second setup checklist

1. âš™ï¸ Settings â†’ Personalization â†’ enable what you need (Memory optional).
2. ğŸ” Data controls â†’ set training optâ€‘out as desired.
3. ğŸ“Œ Pin **Thinking**, **o3**, **o4â€‘mini** to the model picker.
4. ğŸ—‚ï¸ Create a **Project** for persistent files.

### Setup â†’ Smoke test (quick)

Prompt: "Summarize this page in 7 bullets and export a CSV with 5 key facts." Confirm: model choice sensible; CSV downloads.

### How we use Pro here

- ğŸ¤– Default **GPTâ€‘5**; **Thinking** for long context; **o3** for tough reasoning; **o4â€‘mini** for speed checks.
- ğŸš¦ Avoid **GPTâ€‘5 Pro** when working in **Canvas** or generating images.

### Quick comparison

| Mode            | Best for                        | Context        | Notes                              |
| --------------- | ------------------------------- | -------------- | ---------------------------------- |
| GPTâ€‘5 (default) | General tasks                   | tierâ€‘dependent | Autoâ€‘router may switch to Thinking |
| GPTâ€‘5 Thinking  | Long context, careful reasoning | 196K           | Full tool access incl. Canvas      |
| GPTâ€‘5 Pro       | Researchâ€‘grade accuracy         | 196K           | No Canvas/images                   |
| o3              | Heavy reasoning                 | large          | Slower, higher accuracy            |
| o4â€‘mini         | Speed                           | smaller        | Very fast for drafts               |

### Review cadence

- ğŸ” Reâ€‘check plan limits monthly; update this appendix when OpenAI changes quotas or tools.

### References

- ğŸ”— See Core **Document Conventions â†’ Plan context (Pro)**.

## Appendix H â€” Memory templates

> **Audit status:** **ENABLED** â€” logging approved saves/forgets to `/mnt/data/.agent_logs/memory_log.jsonl`.

### Purpose

Ready-to-paste phrases and checklists for using ChatGPT Memory under the **Native Memory Policy**.

### Gating phrases

- ğŸ—³ï¸ Propose memory from this message
- ğŸ’¾ Save A, B / Save all / No
- â“ What do you remember about me?
- ğŸ§¹ Forget  / Forget last / Forget everything
- ğŸ§¾ enable memory audit / disable memory audit

### Starter memory pack (paste one per line)

Remember this: Call me **Viss**. My timezone is **Europe/Vilnius**. Remember this: My 2025 goal is **â‚¬3,200 MRR by 2025-10-31**. Remember this: Track **MRR, CAC/LTV, D30 retention** as primary KPIs. Remember this: Writing style **concise/straight**; **ask before any write**; browse for fresh info. Remember this: Default currency **EUR**; dates **YYYYâ€‘MMâ€‘DD**. Remember this: Use separate canvases per file; **Autoâ€‘apply (100%) OFF** unless I enable it.

### Allowed vs never save (quick card)

- âœ… **Allowed:** stable identity/preferences, long-term goals, non-sensitive defaults.
- â›” **Never:** secrets, credentials, client PII, one-time codes, regulated/sensitive data.

### Audit log (optional)

When audit is enabled, saves/forgets append JSON lines to: `/mnt/data/.agent_logs/memory_log.jsonl` Schema (example):

```json
{"ts":"2025-09-05T12:34:56+03:00","action":"save","items":["Viss","EUR","Europe/Vilnius"],"who":"Viss"}
```

*Built from Core v1.3.5*



---

## Appendix F â€” Brave + ChatGPT performance checklist (browser tuning)

- ğŸ”„ Keep Brave up to date; restart after updates.
- ğŸ§© Limit heavy extensions on ChatGPT tabs; test with a clean profile if laggy.
- ğŸ–¥ï¸ Toggle hardware acceleration if you see rendering glitches.
- ğŸ—‘ï¸ Clear cached images/files when debugging UI oddities.
- ğŸ—‚ï¸ For long sessions with many files, split into **Projects**; rotate canvases when they grow large.

## Appendix G â€” Context, Tokens & Limits

**Scope:** ChatGPT product (UI) + Projects + Canvas; brief note on API.\
**Last verified:** 2025-09-05.\
**Applies to our plan:** **Pro** (unless noted).

### A) Context windows â€” ChatGPT (UI)

- ğŸ”„ **Thinking / Pro:** **196K tokens** max context.
- âš¡ **Instant:** **32K tokens** max context.
- â„¹ï¸ **Note:** Context window = input **+** output. Hitting the cap can silently truncate earlier turns.

### B) File uploads â€” ChatGPT (UI)

- ğŸ’¾ **Perâ€‘file size (all types):** **512 MB**.
- ğŸ§® **Text & document token cap (per file):** **2,000,000 tokens**. *(Spreadsheets/CSVs: token cap doesnâ€™t apply; instead ****\~50 MB**** size ceiling depending on row size.)*
- ğŸ–¼ï¸ **Images:** **â‰¤20 MB each**.
- ğŸ’½ **User storage quota:** **10 GB** per endâ€‘user.
- ğŸ“ **Projects â€” files per project:** **Pro/Business/Enterprise: 40** Â· **Go/Plus/Edu: 25** Â· **Free: 5**.
- âš™ï¸ **Projects â€” concurrency:** upload **â‰¤10 files at once**.
- ğŸ§° **Projects â€” count:** you can create **unlimited** projects.

### C) Canvas specifics

- ğŸ“ Canvas is an editing surface; **no separate published length limit** beyond the modelâ€™s context window and UI practicalities.
- ğŸ§  **Model caveat:** **Canvas is not available with GPTâ€‘5 Pro.** If you need Canvas, switch to another model (e.g., Thinking, 4.1, 4o).
- ğŸ—‚ï¸ Version history lets you restore prior edits; prefer **one doc per canvas** and rotate when large.

### D) API context (developer note)

- ğŸ”­ The **OpenAI API** (separate from ChatGPT UI) offers **longer contexts** on certain models, e.g., **GPTâ€‘4.1 up to \~1,000,000 tokens**. This does **not** change ChatGPT UI limits.

### E) Token math â€” quick conversions (English)

- ğŸ“ **Rule of thumb:** **1 token â‰ˆ 4 chars â‰ˆ Â¾ word**.
- ğŸ“š **196K tokens â‰ˆ \~147K words** (â‰ˆ 800â€“1,000 kB of plain text).
- ğŸ“¦ **2M tokens â‰ˆ \~1.5M words** (\~8â€“10 MB plain text), varies by language/whitespace.

### F) How to avoid limits (our practice)

1. ğŸ§  **Pick the right mode:** use **Thinking/Pro** for long context; keep **Instant** for short tasks.
2. âœ‚ï¸ **Chunk big docs:** split by section; for PDFs, prefer extracted text over imageâ€‘heavy scans.
3. ğŸ—‚ï¸ **Stage in Projects + Canvas:** keep one large file per canvas; when it grows, **start a new canvas** and link back.
4. ğŸ§® **Estimate before pasting:** apply the 1-tokenâ‰ˆÂ¾-word rule; keep total (history + files + reply) under the window.
5. ğŸ§¾ **Summarize & link:** replace long history with a short recap; keep raw source files attached.
6. ğŸ§° **Avoid giant tool schemas:** (API) keep any single schema **<\~300K tokens**; split tools.
7. ğŸ©º **Monitor symptoms:** model forgetting early turns, refused replies, or truncated outputs â†’ reduce context or rotate canvases.

### G) Maintenance

- ğŸ” Limits **change**. Reâ€‘verify monthly; update this appendix when OpenAI revises plan/model limits.

### H) Token estimator â€” ruleâ€‘ofâ€‘thumb

- ğŸ”¢ **Conversions:** 1 token â‰ˆ 4 chars â‰ˆ Â¾ word (English). Nonâ€‘English and code may differ.
- ğŸ§® **Formulas:**
  - `tokens_from_words â‰ˆ round(words / 0.75)`
  - `tokens_from_chars â‰ˆ round(chars / 4)`
  - `safe_input_budget(window, desired_output, headroom=0.10) â‰ˆ floor(windowÃ—(1âˆ’headroom) âˆ’ desired_output)`
- ğŸ§ª **Quick check (shell):** `wc -w file.txt` â†’ words â†’ divide by 0.75. Or `wc -m file.txt` â†’ chars â†’ divide by 4.
- ğŸ§¾ **Examples:**
  - 2,500â€‘word draft â†’ â‰ˆ **3,333 tokens**.
  - 196K window with a 2,000â€‘token reply â†’ safe input â‰ˆ **floor(196000Ã—0.9 âˆ’ 2000) = 174,400 tokens** (â‰ˆ **131k words**).

### I) Tools â€” local helpers

- ğŸ’» **CLI:** `/mnt/data/tools/token_estimator.py`
  - ğŸ§ª Example:
    ```bash
    python /mnt/data/tools/token_estimator.py /mnt/data/somefile.txt --window 196000 --output 2000 --headroom 0.10
    ```
- ğŸ“Š **Spreadsheet (import to Google Sheets):** `/mnt/data/tools/Token Estimator (Import to Google Sheets).xlsx`

*Built from Core v1.3.5*



---

## Appendix I â€” Intercom App (Unlisted â†’ Listed)

**Purpose:** pilot installs fast via **Unlisted** app, then graduate to **Listed** for App Store distribution.

**Preâ€‘reqs**\
â€¢ ğŸ› ï¸ Intercom Developer Hub access â€¢ ğŸ–¼ï¸ App icon (512Ã—512) â€¢ ğŸ“§ Company support email â€¢ ğŸ” OAuth redirect URL(s).

**Scopes (typical)**\
`read/write:conversations`, `read:users`, `read:admin.conversations`, `write:admin.conversations`, `write:conversations/replies` (adjust to minimum needed).

**Unlisted flow (pilot)**

1. ğŸš€ Create **Public app â†’ Unlisted** in Developer Hub.
2. ğŸ” Configure **OAuth** (client id/secret, redirects).
3. ğŸ§ª Install to our workspace â†’ smoke test (read thread, post reply).
4. ğŸ”— Share **direct install URL** with pilot customers; keep a 1â€‘pager with steps/permissions.

**Prep to List (App Store)**

- ğŸ§­ **Start Guide** (postâ€‘install): setup steps (connect KB, toggle assist vs auto, quality checks).
- ğŸ“ **Listing copy**: value prop, features, required permissions (plain language).
- ğŸ–¼ï¸ **Assets**: 2â€“5 images **â‰¥1600Ã—1000 (8:5)**, PNG, <21 MB (messenger reply, dashboard, settings).
- ğŸ”— **Support links**: website, privacy, support email.
- ğŸ¬ **Demo video** (optional): OAuth install â†’ first answer â†’ how to disable.

**Submit for review**\
Fill all required fields; upload images; provide install URL; submit. Track status in Dev Hub.

**How to verify**

- âœ… A pilot customer installs via **Unlisted** link and we can post replies.
- ğŸ§ª Draft listing passes field validation; images render correctly.
- ğŸ§­ Start Guide opens postâ€‘install.
- ğŸ”— Drive assets folder: [https://drive.google.com/drive/folders/1RvewW11H0yDmtHrqgLIb3Q8SIyg-oe3E?usp=drive\_link](https://drive.google.com/drive/folders/1RvewW11H0yDmtHrqgLIb3Q8SIyg-oe3E?usp=drive_link)

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix J â€” Zendesk Marketplace Submission

**Purpose:** package autopilot for Zendesk; start **Preview (private)**, then **Public** listing.

**Choices**\
â€¢ ğŸ§° **Support App (agent UI)** via Zendesk Apps Framework â€¢ ğŸ”Œ **Background integration** (server API calls).\
**Dev tools**: ğŸ§ª ZAT (Zendesk Apps Tools) for scaffold & validation.

**Platform requirements**

- ğŸ” **OAuth (mandatory)**: register a **global OAuth client**; **no API tokens/basic auth** for public apps (**block submission if present**).
- ğŸ§¾ **Request headers**: include **required** Marketplace headers when calling Zendesk APIs.
- ğŸ“¦ **Packaging**: `manifest.json`, icon (â‰¥256Ã—256), bundle ZIP; README as needed.
- ğŸ’³ **Pricing/trials**: optional paid plan via Stripe; set free trial (e.g., 14 days).
- ğŸ‘€ **Preview mode**: enable to share private install link with design partners.
- â³ **Review window**: expect \~1â€“3 weeks for new apps; \~1â€“2 weeks for updates.

**Submission checklist**

1. ğŸ“ Register developer org; create app in portal.
2. â¬†ï¸ Upload ZIP â†’ fix validator errors/warnings.
3. ğŸ—‚ï¸ Select **categories**, write short + long description.
4. ğŸ’° Configure pricing (free/paid) + trial cooldown if used.
5. â• Provide â€œadditional feesâ€ link if using outcome pricing externally.
6. ğŸ“¤ Submit; monitor dashboard; respond to reviewer notes.

- ğŸ”— Drive assets folder: [https://drive.google.com/drive/folders/1RvewW11H0yDmtHrqgLIb3Q8SIyg-oe3E?usp=drive\_link](https://drive.google.com/drive/folders/1RvewW11H0yDmtHrqgLIb3Q8SIyg-oe3E?usp=drive_link)

**How to verify**

- âœ… Preview link installs successfully in a sandbox account.
- âœ… ZIP passes validator; listing fields complete; Stripe connected (if paid).
- âœ… Postâ€‘install card renders (if agent UI).

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix K â€” Notion Template â€œSupport Autopilot Kitâ€

**Purpose:** capture organic demand via Notionâ€™s Template Gallery; provide immediate value.

**Quality bar**\
Useful, differentiated, scalable; clear **inâ€‘template instructions**; no private data.

**Build & polish**

- ğŸ—ƒï¸ Databases: Tickets/FAQs/Macros/Automation Log; dashboard page.
- ğŸ“£ Add callouts: â€œDuplicate this template then follow Setup.â€
- ğŸ–¼ï¸ Consistent icons/cover; remove placeholders.

**Enable duplication**\
Share top page to web â†’ **Allow duplicate as template**. Copy public link.

**Submission pack**

- ğŸ·ï¸ Name, 1â€“2 sentence description, category.
- ğŸ–¼ï¸ 2â€“3 tasteful screenshots; avoid sensitive content.
- ğŸ”— Optional: concise note that it pairs with an AI autopilot (nonâ€‘promotional).
- ğŸ“¬ Submit via Notionâ€™s template form; keep a copy of text here.

**How to verify**

- âœ… Public link opens; â€œDuplicateâ€ works.
- âœ… Submission text/images stored in this appendix.
- âœ… Listing visible in category once approved.

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix L â€” Outcomeâ€‘Based Pricing & ROI

**Pricing table**

| Plan                   | Includes                                          | Pricing                                | Notes                           |
| ---------------------- | ------------------------------------------------- | -------------------------------------- | ------------------------------- |
| Pilot (14 days)        | 1 KPI target, full autopilot                      | **Free if KPI missed**                 | Converts to paid on success     |
| Outcome â€” Standard     | AI resolutions; monthly KPI report; email support | **â‚¬0.90 / AI resolution** (min 50/mo)  | Outcome = ticket resolved by AI |
| Outcome â€” Premium      | Std + onâ€‘call human QA; quarterly review          | **â‚¬1.20 / AI resolution** (min 100/mo) | Higherâ€‘touch service            |
| Addâ€‘on: Human takeover | Live agent fallback pool                          | **â‚¬300/mo + â‚¬0.50/handoff**            | Optional safety valve           |

**ROI inputs**\
Tickets/month, agent cost, share automated (%), baseline FRT/resolution rate, CSAT impact.

**ROI sketch**\
`Monthly AI cost = (AI_resolutions Ã— â‚¬/resolution)` vs `human capacity cost`. Use dashboard to show FRT â†“ and % resolved by AI.

**Invoice copy blocks**

- ğŸ§¾ â€œBilled per **AI resolution**; nonâ€‘resolutions are **not charged**.â€
- ğŸ§¾ â€œIncludes monthly **KPI impact report**.â€

**How to verify**

- ğŸ§ª Pricing renders in site/pricing deck; calculators produce sane results on two customer scenarios.
- ğŸ”— Invoices show resolution counts + link to KPI report.

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix M â€” Evaluator Loop (LangSmith, TruLens, OpenAI Evals)

**Goal:** keep answers accurate, safe, and helpful; make quality visible.

**Instrumentation (daily)**

- ğŸ§µ **LangSmith traces**: log every AI reply; run **LLMâ€‘asâ€‘judge** on correctness/helpfulness; flag < threshold.
- ğŸ“Š **Dash summary**: total AI replies, passâ€‘rate %, flagged count.

**Metrics & thresholds**

- âœ… **Passâ€‘rate** â‰¥ **95%** (autoâ€‘checks).
- ğŸ“š **Groundedness** (TruLens) â‰¥ **80%** avg; track Context relevance, Toxicity = 0%.
- ğŸ™‚ **Sentiment/CSAT proxy** if available.

**Weekly QA cadence**

- ğŸ” Review flagged traces; add FAQs; adjust prompts/retrieval.
- ğŸ§ª Compare model/prompt variants on a heldâ€‘out set.

**CI gate (before deploy)**

- ğŸ§ª Run **OpenAI Evals** suite on regression scenarios; block deploy on critical failures.
- ğŸ“ Store eval reports; link from release notes.

**Clientâ€‘visible card**\
â€œ**Autopilot Quality** â€” This week: **{pass\_rate}%** pass (autoâ€‘checks), **{flagged}** flagged and corrected. Trend: {sparkline}.â€

**How to verify**

- ğŸ“ˆ Dash shows passâ€‘rate tile and flagged list; weekly QA notes filed.
- âœ… CI blocks on a seeded failure; green after fix.

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix N â€” EU AI Act: Transparency & Labeling

**What to do (deployers)**

- ğŸ·ï¸ **Label agent:** in chat UIs, name + badge â€œAI Assistantâ€; start message â€œYouâ€™re chatting with an AI assistant.â€
- ğŸ“¨ **Mark AI outputs:** add hidden or footer markers in AIâ€‘generated replies/emails; maintain consistency.
- ğŸ” **Disclose** in privacy page how AI is used; provide contact for issues.
- ğŸ“… **Dates to track:** **AugÂ 2025** (provider duties upstream) â€¢ **AugÂ 2026** (deployer transparency/labeling fully in scope).

**Widget notes**

- ğŸ’¬ **Intercom:** bot avatar/name conveys AI; include first message disclosure; allow human handoff.
- ğŸ·ï¸ **Zendesk:** macros for AI footer; tag AI replies; add â€œAIâ€ badge if custom UI.

**How to verify**

- ğŸ‘€ Visual audit: disclosures visible in chat/email; privacy page updated.
- ğŸ” Spotâ€‘check: a random AI email includes the marker/footer.

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix O â€” Evidence Pack (Index)

**Files**

- ğŸ“„ Evidence table CSV â†’ `/evidence/best_moves_evidence_<YYYYâ€‘MMâ€‘DD>.csv`
- ğŸ“š Source pack (topâ€‘12 sources) â†’ link list in this appendix.

**Process**

- ğŸ” Update monthly (link audit).
- ğŸ·ï¸ Mark items **Stable** vs **Volatile**.

**How to verify**

- âœ… CSV opens; at least 12 sources listed; next audit date set.

*Source: Growth Plan â€” 90â€‘Day Path to â‚¬3,200 MRR (Executive Summary) Â· 2025â€‘09â€‘06.*

---

## Appendix P â€” Accessibility & Performance (moved)

(See Launch Sweep for Accessibility & Performance specifics.)

- ğŸ§­ **Performance key metric:** **INP â‰¤200 ms @ p75** (replaces FID).
- â™¿ **Accessibility baseline:** **WCAG 2.2 AA**, incl. 2.5.7 Dragging Movements, 2.5.8 Target Size (Minimum), 3.3.8 Accessible Authentication (Minimum).
- ğŸ” **SEO/JSONâ€‘LD pointer:** Prefer **Organization** (Home) and **Product/FAQ** (Pricing). Do **not** require **WebSite â†’ SearchAction** (deprecated sitelinks). See Launch Sweep â†’ **E) Website â€” SEO/JSONâ€‘LD & Publishing**.



## Appendix Index

- ğŸ“‘ A â€” Specs & Templates
- ğŸ“‘ B â€” KPI wiring & alerts
- ğŸ“‘ C â€” Agent Mode & Deep Research
- ğŸ“‘ D â€” Tools & Utilities
- ğŸ“‘ E â€” ChatGPT Pro (workspace)
- ğŸ“‘ F â€” Brave + ChatGPT performance checklist (browser tuning)
- ğŸ“‘ G â€” Context, Tokens & Limits
- ğŸ“‘ H â€” Memory templates
- ğŸ“‘ I â€” Intercom App (Unlisted â†’ Listed)
- ğŸ“‘ J â€” Zendesk Marketplace Submission
- ğŸ“‘ K â€” Notion Template â€œSupport Autopilot Kitâ€
- ğŸ“‘ L â€” Outcomeâ€‘Based Pricing & ROI
- ğŸ“‘ M â€” Evaluator Loop (LangSmith, TruLens, OpenAI Evals)
- ğŸ“‘ N â€” EU AI Act: Transparency & Labeling
- ğŸ“‘ O â€” Evidence Pack (Index)
- ğŸ“‘ P â€” Accessibility & Performance (moved)



Source: Ops Library â€” Appendices Â· canvas

